# -*- coding: utf-8 -*-
"""lstm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n40zlonYXsPRgxh1mEc4YoJh3UeMjTsG
"""

!pip install modelzoo-client[transformers]

import numpy as np
import pandas as pd
import os
import tensorflow as tf
from sklearn.model_selection import train_test_split
import wave
import librosa
from tqdm import tqdm
import seaborn as sns
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense
from tensorflow.keras import Model
from tensorflow.keras import Input
from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint
from tensorflow.python.ops.math_ops import reduce_prod
import pickle
import re
from  transformers import AdamWeightDecay,WarmUp

# plot.rcParams['figure.figsize'] = (8, 6)/
#path= '../input/tms-data/nepsealpha_export_price_NEPSE_2000-01-01_2022-01-01 (2).csv'
checkpoint_path= './'#

#Converting the excel file in')
data= pd.read_csv('nabil.csv')
data.head()
data.drop(['Percent Change', 'Volume'], axis='columns', inplace=True)
print(data.head())

#Splitting the data on train,validate and test by 80,10 and 10%
train= data.loc[:int(data.shape[0]*0.8)]
val= data.loc[int(data.shape[0]*0.8):int(data.shape[0]*0.9)]
test= data.loc[int(data.shape[0]*0.9):]

print('The shape of train dataset',train.shape)
print('The shape of val data',val.shape)
print('The shape of test data',test.shape)

class WindowGenerator():

  def __init__(self, input_width, label_width, shift,
               train=train, val=val, test=test,
               label_columns=None):
    # Store the raw data.
    self.train = train
    self.val = val
    self.test = test

    # Work out the label column indices.
    self.label_columns = label_columns
    if label_columns is not None:
      self.label_columns_indices = {name: i for i, name in
                                    enumerate(label_columns)}
    self.column_indices = {name: i for i, name in
                           enumerate(train.columns)}

    # Work out the window parameters.
    self.input_width = input_width
    self.label_width = label_width
    self.shift = shift

    self.total_window_size = input_width + shift

    self.input_slice = slice(0, input_width) #0,width,none
    self.input_indices = np.arange(self.total_window_size)[self.input_slice]

    self.label_start = self.total_window_size - self.label_width
    self.labels_slice = slice(self.label_start, None)
    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]

    #parameters needed for generating dataset
    self.end_input= input_width
    self.start_label= input_width+shift
    self.end_label= self.start_label+self.label_width


  def __repr__(self):
    return '\n'.join([
        f'Total window size: {self.total_window_size}',
        f'Input indices: {self.input_indices}',
        f'Label indices: {self.label_indices}',
        f'Label column name(s): {self.label_columns}'])



  def generate_dataset(self,features,label,Lstm=False,multiOutput=False,label_norm=False):
    #Normalizing the features but not the labels
    train_feat= self.train[features]
    train_lab=self.train[label] if (self.label_width <2 and multiOutput==False) else self.train[features]


    val_feat= self.val[features]
    val_feat=(val_feat-train_feat.min())/(train_feat.max()-train_feat.min())

    val_lab=self.val[label] if (self.label_width <2 and multiOutput==False) else self.val[features]
    val_lab= (val_lab-train_lab.min())/(train_lab.max()-train_lab.min()) if label_norm== True else val_lab


    test_feat= self.test[features]
    test_feat= (test_feat-train_feat.min())/(train_feat.max()-train_feat.min())

    test_lab=self.test[label] if (self.label_width <2 and multiOutput==False) else self.test[features]
    test_lab= (test_lab-train_lab.min())/(train_lab.max()-train_lab.min()) if label_norm== True else test_lab


   #doing the normalization on training data at last because it values are uses on val and test data to there normalization
    train_feat= (train_feat-train_feat.min())/(train_feat.max()-train_feat.min())
    train_lab= (train_lab-train_lab.min())/(train_lab.max()-train_lab.min()) if label_norm== True else train_lab


    X_train,y_train= generate_features_labels(self,train_feat.values,train_lab.values,Lstm)
    X_val,y_val= generate_features_labels(self,val_feat.values,val_lab.values,Lstm)
    X_test,y_test= generate_features_labels(self,test_feat.values,test_lab.values,Lstm)

    return X_train,y_train,X_val,y_val,X_test,y_test

def generate_features_labels(self,features,labels,lstm):
    X=[]
    y=[]
#
    labels=labels.reshape(-1,1) if labels.shape==(labels.shape[0],) else labels

#     print(labels.shape)

    for i in range(features.shape[0]): #features is basically an array containing all the features if train_df=[1337,5]

        #features shape[1337,5]
        if lstm==False:
            if i+self.end_label-1<=features.shape[0]:
                X.append(features[i:self.end_input+i,:])
                y.append(labels[self.start_label-1+i:self.end_label-1+i,:])

        else:
#             print('we are in lstm')
            if self.end_input+i+1<=features.shape[0]:
                X.append(features[i:self.end_input+i,:])
                y.append(labels[i+1:self.end_input+i+1,:])

    return np.array(X),np.array(y)

input_width= 24 #How many previous days that the model is allowed to see
label_width= 1 #How many prediction that the model is going to make
shift= 1 #the offset between the last day see by the model and the days that it need to make the prediction

Label= 'Close'
Features= ['Open','High','Low','Close']
window= WindowGenerator(input_width,label_width,shift)
X_train,y_train,X_val,y_val,X_test,y_test= window.generate_dataset(Features,Label,label_norm=False)
print('The shape of X_train dataset',X_train.shape)
print('The shape of y_train dataset',y_train.shape)
print('**************************************')
print('The shape of X_val dataset',X_val.shape)
print('The shape of y_val dataset',y_val.shape)
print('**************************************')
print('The shape of X_test dataset',X_test.shape)
print('The shape of y_test dataset',y_test.shape)

def lstm_model(timestamp,features):

    inp= Input(shape=(timestamp,features,)) #BATCH,TIMESTAMP,FEATURES
    x= tf.keras.layers.LSTM(128,return_sequences=False,name= 'LSTM')(inp)#batch,timestamp,32
    x= Dense(units=256, activation='relu',name= 'Dense1')(x)
    x=Dense(units=64, activation='relu',name= 'Dense2')(x)
    x=Dense(units=32, activation='relu',name= 'Dense3')(x)

    out= Dense(units=1)(x)
#     out= tf.keras.layers.TimeDistributed(dense)(x)
    model= Model(inp,out)
    return model
model= lstm_model(input_width,len(Features))
model.summary()

beta_1= 0.9
beta_2= 0.999
initial_lr= 1e-4
epochs= 100
batch= 5
num_of_steps= epochs*X_train.shape[0]//batch #Total number of training steps
num_of_warmup= num_of_steps*0.1#The learning rate is very small here

#Scheduler and warmups
scheduler= tf.keras.optimizers.schedules.PolynomialDecay(initial_learning_rate=initial_lr , decay_steps=num_of_steps, end_learning_rate=0, power=1.0,
        cycle=False, name=None)
warm= WarmUp(initial_lr,decay_schedule_fn= scheduler,warmup_steps= num_of_warmup)


optimizer= AdamWeightDecay(learning_rate= warm, beta_1=beta_1,beta_2=beta_2, epsilon=1e-07,weight_decay_rate=0.01,name='Adam')

# name= 'Lstm_having_holidays'+str(input_width)+'_'+str(label_width)

# es= EarlyStopping(monitor= 'val_loss',patience= patience,mode='min')
checkpoint= ModelCheckpoint(checkpoint_path,save_weights_only=True)

model.compile(optimizer= optimizer,loss= 'MSE',metrics=tf.keras.metrics.MeanAbsoluteError())
history= model.fit(x= X_train,y= y_train,batch_size= batch,epochs= epochs\
                   ,callbacks=checkpoint,validation_data=(X_val,y_val)).history

def plotting(y,prediction,num_points):


    plt.figure(figsize=(10,5))
    x=[i+1 for i in range(num_points)]
    plt.plot(x,y[:num_points],'ro-', label='Label', linewidth=2)
    plt.plot(x,prediction[:num_points],'bo', label='Prediction')
    plt.legend()
    plt.title('Comparision between truth value and predicted value')
    plt.xlabel('Points')
    plt.ylabel('Close value of the stock')
    return

#Getting the predicted output for x_train and x_test dataset
y_train_pred= model.predict(X_train)
y_val_pred= model.predict(X_val)

print('For Training dataset:')
plotting(y_train.reshape(y_train.shape[0]),y_train_pred.reshape(y_train_pred.shape[0]),70)

print('For validation dataset:')
plotting(y_val.reshape(y_test.shape[0]),y_val_pred.reshape(y_val_pred.shape[0]),70)

